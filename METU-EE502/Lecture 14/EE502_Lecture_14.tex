% 


\documentclass[twoside]{article}
\setlength{\oddsidemargin}{0.25 in}
\setlength{\evensidemargin}{-0.25 in}
\setlength{\topmargin}{-0.6 in}
\setlength{\textwidth}{6.5 in}
\setlength{\textheight}{8.5 in}
\setlength{\headsep}{0.75 in}
\setlength{\parindent}{0 in}
\setlength{\parskip}{0.1 in}

%
% ADD PACKAGES here:
%

\usepackage{amsmath,amsfonts,graphicx,arydshln}


\newcounter{lecnum}
\renewcommand{\thepage}{\thelecnum-\arabic{page}}
\renewcommand{\thesection}{\thelecnum.\arabic{section}}
\renewcommand{\theequation}{\thelecnum.\arabic{equation}}
\renewcommand{\thefigure}{\thelecnum.\arabic{figure}}
\renewcommand{\thetable}{\thelecnum.\arabic{table}}

%
% The following macro is used to generate the header.
%
\newcommand{\lecture}[4]{
   \pagestyle{myheadings}
   \thispagestyle{plain}
   \newpage
   \setcounter{lecnum}{#1}
   \setcounter{page}{1}
   \noindent
   \begin{center}
   \framebox{
      \vbox{\vspace{2mm}
    \hbox to 6.28in { {\bf EE502 - Linear Systems Theory II
	\hfill Spring 2023} }
       \vspace{4mm}
       \hbox to 6.28in { {\Large \hfill Lecture #1 \hfill} }
       \vspace{2mm}
       \hbox to 6.28in { {\it Lecturer: #2 \hfill } }
      \vspace{2mm}}
   }
   \end{center}
   \markboth{Lecture #1}{Lecture #1}

   \vspace*{4mm}
}

\renewcommand{\cite}[1]{[#1]}
\def\beginrefs{\begin{list}%
        {[\arabic{equation}]}{\usecounter{equation}
         \setlength{\leftmargin}{2.0truecm}\setlength{\labelsep}{0.4truecm}%
         \setlength{\labelwidth}{1.6truecm}}}
\def\endrefs{\end{list}}
\def\bibentry#1{\item[\hbox{[#1]}]}


\newcommand{\fig}[3]{
			\vspace{#2}
			\begin{center}
			Figure \thelecnum.#1:~#3
			\end{center}
	}

% Use these for theorems, lemmas, proofs, etc.
\newtheorem{theorem}{Theorem}[lecnum]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newenvironment{proof}{{\bf Proof:}}{\hfill\rule{2mm}{2mm}}
\newtheorem{exmp}[theorem]{Ex}

% **** IF YOU WANT TO DEFINE ADDITIONAL MACROS FOR YOURSELF, PUT THEM HERE:

\begin{document}

% Lecture Details
\lecture{14}{Asst. Prof. M. Mert Ankarali}

%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{State Observer}

Generally the full state measurment,$x(t)$ or $x[k]$, of a system is not accessible and \textit{observers, estimators, filters})
have to be used to extract this information. The output, $y(t)$ or $y[k]$, represents the actual measurements
which is a function of the input and the output. We will mainly focus on DT systems in this lecture however, 
all of the derivations and concepts are either same with the CT case or can be easily adopted with minor modifications. Let 
%
\begin{align*}
  x[k+1] &= A x[k] + B u[k]
  \\
  y[k] &= C x[k] + D u[k]
\end{align*}
%
A Luenberger observer is built using a ``simulated'' model of the 
system and the errors caused by the mismatched initial conditions 
$x_0 \neq \hat{x}_0$ (or other types of perturbations)
are reduced by introducing output error feedback.

Let's assume that the state vector of the simulated system
is $\hat{x}[k]$, then the state space equation of this
synthetic system takes the form
%
\begin{align*}
  \hat{x}[k+1] &= A \hat{x}[k] + B u[k]
  \\
  \hat{y}[k] &= C \hat{x}[k] + D u[k]
\end{align*}
%
Note that since $u[k]$ is the input that is supplied by the 
controller, we assume that it is known apriori. If $x[0] = \hat{x}[0]$ and
when there is no model mismatch or uncertainty in the system
then we expect that $x[k] = \hat{x}[k]$ and $y[k] = \hat{y}[k]$ 
for all $k$. When $x[0] \neq \hat{x}[0]$, then we should observe a 
difference between the measured and predicted output
$y[k] \neq \hat{y}[k]$. The core idea in Luenberger observer
is feeding the error in the output prediction 
$y[k] - \hat{y}[k]$ to the simulated system via a linear feedback gain.
%
\begin{align*}
  \hat{x}[k+1] &= A \hat{x}[k] + B u[k] + L \left( y[k] - \hat{y}[k] \right) 
  \\
  \hat{y}[k] &= C \hat{x}[k] + D u[k]
\end{align*}
%
In order to understand how a Luenberger observer works and
to choose a proper observer gain $L$, we define an error signal
$e[k] = x[k] - \hat{x}[k]$. The dynamics w.r.t $e[k]$ can be derived
as
%
\begin{align*}
  e[k+1] &= x[k+1] - \hat{x}[k+1]
        \\
     &= \left( A x[k] + B u[k] \right)
  - \left( A \hat{x}[k] + B u[k] + L \left( y[k] - \hat{y}[k] \right)
       \right)
\\
   e[k+1] &= \left( A - L C \right) e[k]
\end{align*}
%
where $e[0] = x[0] - \hat{x}[0]$ denotes the error in the initial
condition. 

If the matrix $\left( A - L C \right)$ is stable then the errors in
initial condition will diminish eventually. Moreover, in order
to have a good observer/estimator performance the observer
convergence should be sufficiently fast. 

\textbf{Theorem: (Observer Eigenvalue Placement)} Given $(A,C)$, $\exists L$ s.t. 
%
\begin{align*}
	\mathrm{det}\left[ \lambda I - (A - L C ) \right] &= \lambda^n + a_{n-1}^*  \lambda^{n-1}
	+ \cdots + a_{1}^* \lambda + a_0^*
	\\
	\forall \mathcal{A} &= \lbrace a_0^* , \, a_1^* \, \cdots \, a_{n-1}^* \rbrace , \, a_i^* \in \mathbb{R}
\end{align*} 
%
if and only if $(A,C)$ is observable. 

\textbf{Proof of necessity: } Let's assume that $(A,C)$ not observable and $\exists (\lambda_u , v_u)$ pair such that
$A v_u = v_u \lambda_u $ and $C v_u = 0$. Now check weather $v_u$ is a right eigenvector of $(A - L C)$
%
\begin{align*}
	 (A - L C ) v_u &= A v_u - L C v_U = A v_u = \lambda_u v_U
	\\
        C v_u  &= 0
\end{align*} 
%
Here not only we showed that $\lambda_u$ can not be moved hence it is not possible to locate the observer poles to
arbitrary locations, we also showed that state-observer rule does not affect the observability.

\textbf{Proof of sufficiency:} Note that if $(A,C)$ pair is observable then $(A^T,C^T)$ pair is reachable. Then we know that 
$\exists L^T$ s.t. 
%
\begin{align*}
	\mathrm{det}\left[ \lambda I - (A^T - C^T L^T ) \right] &= \lambda^n + a_{n-1}^*  \lambda^{n-1}
	+ \cdots + a_{1}^* \lambda + a_0^* 
	\\
	\forall \mathcal{A} &= \lbrace a_0^* , \, a_1^* \, \cdots \, a_{n-1}^* \rbrace , \, a_i^* \in \mathbb{R}
\end{align*} 
%
and obviously 
%
\begin{align*}
	\mathrm{det}\left[ \lambda I - (A^T - C^T L^T ) \right] &= \mathrm{det}\left[ \lambda I - (A - L C ) \right] 
\end{align*} 
%
which completes the proof.

\section{Detectability}

The dual of stabilizability in the observability domain is called detectability. 

\textbf{Theorem} The following statements are equal 
\begin{itemize}
\item $(A,C)$ is detectable $\iff$
\item if unobservable modes of $(A,C)$ are asymptotically stable $\iff$
\item $\forall (\lambda_i , v_i)$ s.t. $A v_i = \lambda_i v_i$ $\iff$
and $\mathrm{Re}\lbrace \lambda_i \rbrace \geq 0$ (or $|\lambda_i|\geq0$),
$v_i \notin \mathcal{N}(C)$ $\iff$
\item $\mathrm{rank}\left[ \begin{array}{c} A - \lambda I \\ \hline C \end{array} \right] = n$,
$\forall \lambda \in \mathbb{C}$ s.t. $\mathrm{Re}\lbrace \lambda_i \rbrace \geq 0$ for CT systems (or $\forall \lambda \in \mathbb{C}$ s.t. $|\lambda|  \geq 1$ for DT systems)
\item $\exists L$ such that $(A - L C)$ is asymptotically stable
\end{itemize}

% **** This ENDS THE EXAMPLES. DON'T DELETE THE FOLLOWING LINE:
\end{document}
